{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyOC9A8LY9BnpmfOzRqrQ35y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3fZBNbmjObxI","executionInfo":{"status":"ok","timestamp":1766560815353,"user_tz":-540,"elapsed":25465,"user":{"displayName":"Jae-rak Lim","userId":"07389028510183528444"}},"outputId":"633224a4-273a-4a56-ca38-2df3080fbd24"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["!pip -q install ultralytics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5K5LKPIlO2AD","executionInfo":{"status":"ok","timestamp":1766560855543,"user_tz":-540,"elapsed":4035,"user":{"displayName":"Jae-rak Lim","userId":"07389028510183528444"}},"outputId":"d6b68d0e-a0b6-4e12-c771-19b83f6ecd94"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1MIYde61jLu8X4NzJGXioWHSB__2WQo2f"},"id":"-KAPZxqOOURw","executionInfo":{"status":"ok","timestamp":1766561095853,"user_tz":-540,"elapsed":240287,"user":{"displayName":"Jae-rak Lim","userId":"07389028510183528444"}},"outputId":"f36e32ff-c764-47e8-cde1-2e3d904a037f"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["# ============================================================\n","# YOLO(ultralytics) + ResNet18 분류모델\n","# - validation/00-damage(파손) / validation/01-whole(정상) 검증\n","# - 각 모델별 Accuracy, F1, Confusion Matrix\n","# - (정상/파손)별로 \"정상추론 10개\" + \"오추론 10개\" 시각화\n","# ============================================================\n","\n","# ---- (0) 설치/임포트 ----\n","# Colab에서 ultralytics가 없으면 아래 설치가 필요합니다.\n","# !pip -q install ultralytics\n","\n","import os\n","import random\n","from pathlib import Path\n","\n","import numpy as np\n","from PIL import Image\n","\n","import torch\n","import torch.nn as nn\n","from torchvision import models, transforms\n","\n","import matplotlib.pyplot as plt\n","\n","from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n","\n","# YOLO\n","from ultralytics import YOLO\n","\n","\n","# ---- (1) 경로 설정 ----\n","YOLO_WEIGHT = Path(\"/content/gdrive/MyDrive/01.DS Part/99.Study/(share)HDMF_AUTO_SPOKE/SUBJECT/WEEK2_CAR_DAMAGE_DETECTION/JR/01.Model/(25.12.24)_yolo_best_weight.pt\")\n","RESNET_WEIGHT = Path(\"/content/gdrive/MyDrive/01.DS Part/99.Study/(share)HDMF_AUTO_SPOKE/SUBJECT/WEEK2_CAR_DAMAGE_DETECTION/JR/01.Model/(25.12.24)_resnet18_best.pt\")\n","\n","VAL_DAMAGE_DIR = Path(\"/content/gdrive/MyDrive/01.DS Part/99.Study/01.Vehicle_Damage_Detection/00. Datasets/Kaggle(Car damage detection)/validation/00-damage\")\n","VAL_WHOLE_DIR  = Path(\"/content/gdrive/MyDrive/01.DS Part/99.Study/01.Vehicle_Damage_Detection/00. Datasets/Kaggle(Car damage detection)/validation/01-whole\")\n","\n","assert YOLO_WEIGHT.exists(), f\"YOLO weight not found: {YOLO_WEIGHT}\"\n","assert RESNET_WEIGHT.exists(), f\"ResNet weight not found: {RESNET_WEIGHT}\"\n","assert VAL_DAMAGE_DIR.exists(), f\"Validation damage dir not found: {VAL_DAMAGE_DIR}\"\n","assert VAL_WHOLE_DIR.exists(),  f\"Validation whole dir not found: {VAL_WHOLE_DIR}\"\n","\n","# 라벨 정의 (통일)\n","# 0 = damage, 1 = whole\n","LABEL_MAP = {\"damage\": 0, \"whole\": 1}\n","INV_LABEL = {0: \"damage\", 1: \"whole\"}\n","\n","\n","# ---- (2) 유틸: 이미지 파일 수집 ----\n","IMG_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\"}\n","\n","def list_images(folder: Path):\n","    paths = []\n","    for p in folder.rglob(\"*\"):\n","        if p.is_file() and p.suffix.lower() in IMG_EXTS:\n","            paths.append(p)\n","    return sorted(paths)\n","\n","damage_imgs = list_images(VAL_DAMAGE_DIR)\n","whole_imgs  = list_images(VAL_WHOLE_DIR)\n","\n","print(f\"[INFO] damage images: {len(damage_imgs)}\")\n","print(f\"[INFO] whole  images: {len(whole_imgs)}\")\n","\n","all_paths = damage_imgs + whole_imgs\n","all_y_true = ([LABEL_MAP[\"damage\"]] * len(damage_imgs)) + ([LABEL_MAP[\"whole\"]] * len(whole_imgs))\n","\n","\n","# ---- (3) 디바이스 ----\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"[INFO] device = {device}\")\n","\n","\n","# ---- (4) ResNet18 로더 (binary classifier 가정) ----\n","# ⚠️ 주의:\n","# - 학습 때 마지막 레이어를 (num_classes=2)로 바꿔 저장했다면 아래 코드로 로드됩니다.\n","# - 만약 state_dict 저장 시 키가 다르거나, FC 구조가 다르면 에러가 날 수 있습니다.\n","#   그 경우 출력되는 에러 메시지 기준으로 fc 이름/차원을 맞춰주면 됩니다.\n","\n","def load_resnet18_binary(weight_path: Path, device):\n","    model = models.resnet18(weights=None)   # 가중치 파일을 직접 로드하므로 weights=None\n","    model.fc = nn.Linear(model.fc.in_features, 2)\n","    ckpt = torch.load(weight_path, map_location=\"cpu\")\n","\n","    # state_dict 형태 다양성 대응\n","    if isinstance(ckpt, dict) and \"state_dict\" in ckpt:\n","        state_dict = ckpt[\"state_dict\"]\n","    elif isinstance(ckpt, dict) and \"model_state_dict\" in ckpt:\n","        state_dict = ckpt[\"model_state_dict\"]\n","    elif isinstance(ckpt, dict) and any(k.startswith(\"module.\") for k in ckpt.keys()):\n","        state_dict = ckpt\n","    else:\n","        state_dict = ckpt\n","\n","    # module. prefix 제거(DDP/DP 저장 대비)\n","    new_state = {}\n","    for k, v in state_dict.items():\n","        nk = k.replace(\"module.\", \"\")\n","        new_state[nk] = v\n","\n","    model.load_state_dict(new_state, strict=True)\n","    model.eval().to(device)\n","    return model\n","\n","resnet = load_resnet18_binary(RESNET_WEIGHT, device)\n","\n","# ResNet 전처리 (ImageNet 기준)\n","resnet_tf = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(\n","        mean=[0.485, 0.456, 0.406],\n","        std=[0.229, 0.224, 0.225]\n","    ),\n","])\n","\n","\n","# ---- (5) YOLO 로더 ----\n","yolo = YOLO(str(YOLO_WEIGHT))\n","\n","\n","# ---- (6) 예측 함수들 ----\n","@torch.no_grad()\n","def predict_resnet_batch(paths, model, device, batch_size=64):\n","    preds = []\n","    for i in range(0, len(paths), batch_size):\n","        batch_paths = paths[i:i+batch_size]\n","        imgs = []\n","        for p in batch_paths:\n","            img = Image.open(p).convert(\"RGB\")\n","            imgs.append(resnet_tf(img))\n","        x = torch.stack(imgs, dim=0).to(device)\n","        logits = model(x)\n","        pred = torch.argmax(logits, dim=1).detach().cpu().numpy().tolist()\n","        preds.extend(pred)\n","    return preds\n","\n","\n","def predict_yolo(paths, yolo_model, imgsz=640, conf=0.25, device_str=None):\n","    \"\"\"\n","    Ultralytics YOLO 'classify' head로 학습한 모델을 가정합니다.\n","    - 결과에서 top1 클래스(정수)를 꺼내 예측으로 사용합니다.\n","    \"\"\"\n","    preds = []\n","    # device_str: \"0\" or \"cpu\" 등. None이면 ultralytics가 자동 선택\n","    results = yolo_model.predict(\n","        source=[str(p) for p in paths],\n","        imgsz=imgsz,\n","        conf=conf,\n","        verbose=False,\n","        device=device_str\n","    )\n","    for r in results:\n","        # classify model의 경우: r.probs.top1 제공\n","        if hasattr(r, \"probs\") and r.probs is not None:\n","            preds.append(int(r.probs.top1))\n","        else:\n","            raise RuntimeError(\n","                \"YOLO 결과에서 r.probs를 찾지 못했습니다. \"\n","                \"이 가중치가 'classification' 모델이 아닌지 확인해 주세요.\"\n","            )\n","    return preds\n","\n","\n","# ---- (7) 평가/리포트 함수 ----\n","def evaluate_and_report(y_true, y_pred, title=\"Model\"):\n","    acc = accuracy_score(y_true, y_pred)\n","    f1  = f1_score(y_true, y_pred, average=\"binary\", pos_label=LABEL_MAP[\"damage\"])  # damage를 positive로\n","    cm  = confusion_matrix(y_true, y_pred, labels=[0,1])\n","    print(\"=\"*70)\n","    print(f\"[{title}]\")\n","    print(f\"Accuracy: {acc:.4f}\")\n","    print(f\"F1 (pos=damage): {f1:.4f}\")\n","    print(\"Confusion Matrix (rows=true, cols=pred) labels=[damage(0), whole(1)]\")\n","    print(cm)\n","    print(\"\\nClassification report:\")\n","    print(classification_report(y_true, y_pred, target_names=[\"damage(0)\", \"whole(1)\"]))\n","    return acc, f1, cm\n","\n","\n","# ---- (8) 시각화(그리드) ----\n","def sample_paths(paths, k=10, seed=42):\n","    if len(paths) == 0:\n","        return []\n","    rng = random.Random(seed)\n","    if len(paths) <= k:\n","        return paths\n","    return rng.sample(paths, k)\n","\n","def show_image_grid(paths, title, ncols=5, figsize=(16, 7)):\n","    if len(paths) == 0:\n","        print(f\"[WARN] {title}: 표시할 이미지가 없습니다.\")\n","        return\n","    n = len(paths)\n","    ncols = min(ncols, n)\n","    nrows = int(np.ceil(n / ncols))\n","    plt.figure(figsize=figsize)\n","    for i, p in enumerate(paths):\n","        ax = plt.subplot(nrows, ncols, i+1)\n","        img = Image.open(p).convert(\"RGB\")\n","        ax.imshow(img)\n","        ax.set_title(p.name, fontsize=9)\n","        ax.axis(\"off\")\n","    plt.suptitle(title, fontsize=14)\n","    plt.tight_layout()\n","    plt.show()\n","\n","def make_correct_wrong_sets(paths, y_true, y_pred):\n","    \"\"\"\n","    (정상/파손) 별로\n","    - 정상추론(correct)\n","    - 오추론(wrong)\n","    리스트를 반환\n","    \"\"\"\n","    damage_correct, damage_wrong = [], []\n","    whole_correct, whole_wrong   = [], []\n","\n","    for p, yt, yp in zip(paths, y_true, y_pred):\n","        if yt == LABEL_MAP[\"damage\"]:\n","            if yp == yt:\n","                damage_correct.append(p)\n","            else:\n","                damage_wrong.append(p)\n","        else:  # whole\n","            if yp == yt:\n","                whole_correct.append(p)\n","            else:\n","                whole_wrong.append(p)\n","    return damage_correct, damage_wrong, whole_correct, whole_wrong\n","\n","\n","# ---- (9) 실행: ResNet 평가 + 시각화 ----\n","print(\"\\n\\n[RUN] ResNet18 inference...\")\n","resnet_pred = predict_resnet_batch(all_paths, resnet, device, batch_size=64)\n","evaluate_and_report(all_y_true, resnet_pred, title=\"ResNet18 (best.pt)\")\n","\n","d_c, d_w, w_c, w_w = make_correct_wrong_sets(all_paths, all_y_true, resnet_pred)\n","\n","show_image_grid(sample_paths(d_c, 10, seed=1), \"ResNet - DAMAGE(파손) correct (up to 10)\")\n","show_image_grid(sample_paths(d_w, 10, seed=2), \"ResNet - DAMAGE(파손) wrong (up to 10)\")\n","show_image_grid(sample_paths(w_c, 10, seed=3), \"ResNet - WHOLE(정상) correct (up to 10)\")\n","show_image_grid(sample_paths(w_w, 10, seed=4), \"ResNet - WHOLE(정상) wrong (up to 10)\")\n","\n","\n","# ---- (10) 실행: YOLO 평가 + 시각화 ----\n","print(\"\\n\\n[RUN] YOLO inference...\")\n","# ultralytics 내부에서 cuda를 잘 잡지만, 필요하면 device_str=\"0\" 또는 \"cpu\"로 고정 가능\n","device_str = \"0\" if torch.cuda.is_available() else \"cpu\"\n","\n","yolo_pred = predict_yolo(all_paths, yolo, imgsz=640, conf=0.25, device_str=device_str)\n","evaluate_and_report(all_y_true, yolo_pred, title=\"YOLO (best_weight.pt)\")\n","\n","d_c, d_w, w_c, w_w = make_correct_wrong_sets(all_paths, all_y_true, yolo_pred)\n","\n","show_image_grid(sample_paths(d_c, 10, seed=11), \"YOLO - DAMAGE(파손) correct (up to 10)\")\n","show_image_grid(sample_paths(d_w, 10, seed=12), \"YOLO - DAMAGE(파손) wrong (up to 10)\")\n","show_image_grid(sample_paths(w_c, 10, seed=13), \"YOLO - WHOLE(정상) correct (up to 10)\")\n","show_image_grid(sample_paths(w_w, 10, seed=14), \"YOLO - WHOLE(정상) wrong (up to 10)\")\n","\n","\n","# ============================================================\n","# (옵션) 오추론 파일명을 따로 보고 싶으면 아래를 실행하세요.\n","# ============================================================\n","def print_misclassified(paths, y_true, y_pred, max_show=30):\n","    mis = []\n","    for p, yt, yp in zip(paths, y_true, y_pred):\n","        if yt != yp:\n","            mis.append((p, yt, yp))\n","    print(f\"[INFO] misclassified = {len(mis)}\")\n","    for i, (p, yt, yp) in enumerate(mis[:max_show]):\n","        print(f\"{i+1:02d}. {p} | true={INV_LABEL[yt]} pred={INV_LABEL[yp]}\")\n","    return mis\n","\n","# 예: ResNet 오추론 목록\n","# _ = print_misclassified(all_paths, all_y_true, resnet_pred, max_show=50)\n","\n","# 예: YOLO 오추론 목록\n","# _ = print_misclassified(all_paths, all_y_true, yolo_pred, max_show=50)\n"]},{"cell_type":"code","source":[],"metadata":{"id":"epq_gX7cO05w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"64KT8ROVOndL"},"execution_count":null,"outputs":[]}]}